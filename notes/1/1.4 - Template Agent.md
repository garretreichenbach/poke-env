# TemplateAgent Structure

## Overview

The `TemplateAgent` is a subclass of `LLMAgentBase` that serves as a template for creating custom LLM-powered Pokémon battling agents. It provides a skeleton that you need to fill with your specific LLM integration code.

## Class Structure

```python
class TemplateAgent(LLMAgentBase):
    """Uses Template AI API for decisions."""
    def __init__(self, api_key: str = None, model: str = "model-name", *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.model = model
        self.template_client = TemplateModelProvider(api_key=...)
        self.template_tools = list(self.standard_tools.values())

    async def _get_llm_decision(self, battle_state: str) -> Dict[str, Any]:
        """Sends state to the LLM and gets back the function call decision."""
        system_prompt = (
            "You are a ..."
        )
        user_prompt = f"..."

        try:
            response = await self.template_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
            )
            message = response.choices[0].message
            
            return {"decision": {"name": function_name, "arguments": arguments}}

        except Exception as e:
            print(f"Unexpected error during call: {e}")
            return {"error": f"Unexpected error: {e}"}
```

## Key Components to Implement

1. **API Client Initialization**:
   - Replace `TemplateModelProvider` with your chosen LLM's API client
   - Configure authentication (API keys)
   - Set up any client-specific parameters

2. **System Prompt Design**:
   - Create a comprehensive system prompt that:
     - Explains the Pokémon battle mechanics
     - Describes the agent's role
     - Provides strategy guidelines
     - Explains the available tools and their proper usage

3. **User Prompt Formatting**:
   - Format the battle state information into a clear prompt
   - Include relevant context from previous turns if needed
   - Structure the information in a way that's easy for the LLM to parse

4. **API Call Implementation**:
   - Make the actual API call to your chosen LLM provider
   - Handle rate limits, timeouts, and other API-specific issues
   - Parse the response correctly

5. **Response Processing**:
   - Extract the function call and arguments from the LLM's response
   - Format it into the expected return structure
   - Validate the response to ensure it's usable

6. **Error Handling**:
   - Implement robust error handling for API issues
   - Have fallback strategies when the LLM fails to provide a valid response
   - Log errors appropriately for debugging

## Implementation Considerations

### LLM Selection
- Choose an LLM with good function calling capabilities
- Consider the context window size needed for battle history
- Balance response speed with decision quality

### Prompt Engineering
- Be explicit about the format you expect from the LLM
- Include examples of good responses in your system prompt
- Provide the LLM with clear guidelines on evaluating battle situations

### Battle State Representation
- Consider what information is most critical for decision-making
- Structure the battle state in a way that highlights important factors
- Consider including type effectiveness information to help the LLM

### Performance Optimization
- Keep prompts concise to reduce token usage
- Consider caching repeated information
- Implement timeouts to prevent battles from stalling

## Example Implementation Steps

1. Choose your LLM provider (OpenAI, Anthropic, etc.)
2. Create API client setup code
3. Design your system prompt
4. Implement the user prompt formatting
5. Add the API call implementation
6. Create response parsing and validation logic
7. Add comprehensive error handling
8. Test with simple battle scenarios
9. Iterate and improve based on performance